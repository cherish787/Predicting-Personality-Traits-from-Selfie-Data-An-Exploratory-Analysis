# -*- coding: utf-8 -*-
"""Untitled83.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1znSjyvpirVbg-UCeH_fTO-NMUI4otina
"""



import pandas as pd
df = pd.read_csv('ai_personality_selfie_dataset.csv')
display(df.head())

import matplotlib.pyplot as plt
import seaborn as sns

# Set the style of the visualizations
sns.set_style("whitegrid")

# Create histograms for the personality scores
plt.figure(figsize=(15, 10))

plt.subplot(2, 3, 1)
sns.histplot(df['extroversion_score'], kde=True, bins=20)
plt.title('Distribution of Extroversion Score')

plt.subplot(2, 3, 2)
sns.histplot(df['confidence_level'], kde=True, bins=20)
plt.title('Distribution of Confidence Level')

plt.subplot(2, 3, 3)
sns.histplot(df['trustworthiness_score'], kde=True, bins=20)
plt.title('Distribution of Trustworthiness Score')

plt.subplot(2, 3, 4)
sns.histplot(df['smile_intensity'], kde=True, bins=20)
plt.title('Distribution of Smile Intensity')

plt.subplot(2, 3, 5)
sns.histplot(df['eye_contact_score'], kde=True, bins=20)
plt.title('Distribution of Eye Contact Score')

plt.tight_layout()
plt.show()

# Box plots for personality scores by gender
plt.figure(figsize=(15, 10))

plt.subplot(2, 3, 1)
sns.boxplot(x='gender', y='extroversion_score', data=df)
plt.title('Extroversion Score by Gender')

plt.subplot(2, 3, 2)
sns.boxplot(x='gender', y='confidence_level', data=df)
plt.title('Confidence Level by Gender')

plt.subplot(2, 3, 3)
sns.boxplot(x='gender', y='trustworthiness_score', data=df)
plt.title('Trustworthiness Score by Gender')

plt.subplot(2, 3, 4)
sns.boxplot(x='gender', y='smile_intensity', data=df)
plt.title('Smile Intensity by Gender')

plt.subplot(2, 3, 5)
sns.boxplot(x='gender', y='eye_contact_score', data=df)
plt.title('Eye Contact Score by Gender')

plt.tight_layout()
plt.show()

# Box plots for personality scores by age range
plt.figure(figsize=(15, 10))

plt.subplot(2, 3, 1)
sns.boxplot(x='age_range', y='extroversion_score', data=df)
plt.title('Extroversion Score by Age Range')
plt.xticks(rotation=45)

plt.subplot(2, 3, 2)
sns.boxplot(x='age_range', y='confidence_level', data=df)
plt.title('Confidence Level by Age Range')
plt.xticks(rotation=45)

plt.subplot(2, 3, 3)
sns.boxplot(x='age_range', y='trustworthiness_score', data=df)
plt.title('Trustworthiness Score by Age Range')
plt.xticks(rotation=45)

plt.subplot(2, 3, 4)
sns.boxplot(x='age_range', y='smile_intensity', data=df)
plt.title('Smile Intensity by Age Range')
plt.xticks(rotation=45)

plt.subplot(2, 3, 5)
sns.boxplot(x='age_range', y='eye_contact_score', data=df)
plt.title('Eye Contact Score by Age Range')
plt.xticks(rotation=45)

plt.tight_layout()
plt.show()

# Box plots for personality scores by emotion category
plt.figure(figsize=(15, 10))

plt.subplot(2, 3, 1)
sns.boxplot(x='emotion_category', y='extroversion_score', data=df)
plt.title('Extroversion Score by Emotion')
plt.xticks(rotation=45)

plt.subplot(2, 3, 2)
sns.boxplot(x='emotion_category', y='confidence_level', data=df)
plt.title('Confidence Level by Emotion')
plt.xticks(rotation=45)

plt.subplot(2, 3, 3)
sns.boxplot(x='emotion_category', y='trustworthiness_score', data=df)
plt.title('Trustworthiness Score by Emotion')
plt.xticks(rotation=45)

plt.subplot(2, 3, 4)
sns.boxplot(x='emotion_category', y='smile_intensity', data=df)
plt.title('Smile Intensity by Emotion')
plt.xticks(rotation=45)

plt.subplot(2, 3, 5)
sns.boxplot(x='emotion_category', y='eye_contact_score', data=df)
plt.title('Eye Contact Score by Emotion')
plt.xticks(rotation=45)

plt.tight_layout()
plt.show()

# Create a copy of the dataframe to avoid modifying the original
df_encoded = df.copy()

# Perform one-hot encoding on the categorical features
df_encoded = pd.get_dummies(df_encoded, columns=['gender', 'age_range', 'emotion_category'], drop_first=True)

display(df_encoded.head())

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, r2_score

# Define the features (X) and the target (y)
features = [col for col in df_encoded.columns if col not in ['image_id', 'user_selfie', 'extroversion_score', 'model_used']]
X = df_encoded[features]
y = df_encoded['extroversion_score']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and train the Random Forest Regressor model
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = rf_model.predict(X_test)

# Evaluate the model
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Absolute Error: {mae}")
print(f"R-squared: {r2}")

# Get feature importances
importances = rf_model.feature_importances_
feature_names = X.columns

# Create a DataFrame for visualization
feature_importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})
feature_importance_df = feature_importance_df.sort_values(by='importance', ascending=False)

# Plot the feature importances
plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=feature_importance_df)
plt.title('Feature Importances for Predicting Extroversion Score')
plt.show()

from sklearn.linear_model import LinearRegression

# Initialize and train the Linear Regression model
lr_model = LinearRegression()
lr_model.fit(X_train, y_train)

# Make predictions on the test set
y_pred_lr = lr_model.predict(X_test)

# Evaluate the model
mae_lr = mean_absolute_error(y_test, y_pred_lr)
r2_lr = r2_score(y_test, y_pred_lr)

print(f"Linear Regression Mean Absolute Error: {mae_lr}")
print(f"Linear Regression R-squared: {r2_lr}")